{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_features = pd.read_csv(\"cleaned_imputed_features.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = cleaned_features.GENTRIFIED.values #instantiate target array before dropping GENTRIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_features.drop('GENTRIFIED', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 27,  13,   7,  13,  14,  15,   6,  20,  29,  22,  58,  28,  37,\n",
       "        33,  34,  27,  18,   6,   6,  14,   8,   0,  38,  40,  59,   0,\n",
       "        10,  27,   0,   0,  16,  11,   0,   0,   0,   3,  29,  18,  10,\n",
       "         0,   0,   3,   0,   7,  13,   0,  24,  25,   0,   0,   0,   0,\n",
       "         0,  21,  16,  66,   0,   0,   0,   0,   0,   0,  14,   0,   0,\n",
       "         0,   0,   0,   0,   0,  13,   0,  14,  31,   0,   0,   0,   6,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  20,   0,\n",
       "         0,  54,   0,   0,   0, 100,   0,  45,  29,  38,   0,  15,  23,\n",
       "        14,   0,   0,  33,  35,  22,   5,  23,  23,  17,  53,   0,  30,\n",
       "        33,  76,  28,  11,  28,   0,  18,  11,   0,   0,   0,   2,   9,\n",
       "        23,   9,   5,   0,   3,   4,  13,   5,   0,  39,  58,   0,   0,\n",
       "         0,   0,   0,  19,  32,   0,  32,  21,  76,  15,   0,   0,   8,\n",
       "         0,   0,   0,   0,   0,   0,  31,   0,   0,   0,   0,   0,   0,\n",
       "         0,  22,   0,   0,   0,   0,   0,   0,   0,   0,  14,   0,  17,\n",
       "         6,  18,  14,  14,   0,   0,   0,   0,   0,   4,   0,   0,   8,\n",
       "         0,  32,  19,   0,  25,  11,  28,   2,  47,  28,  22,  27,  28,\n",
       "        21,  28,  28,   3,  52,   0,   0,   0,  11,   0,   0,   0,  32,\n",
       "        21,  20,   9,   0,  12,   0,  24,  22,  26,  17,  21,  80,   8,\n",
       "        44,  41, 100,  21,   4,   5,   0,  41,   0,   0,   0,  27,  17,\n",
       "        21,  80,   4,   0,   0,   0,  33,  20,  17,  80,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  10,   0,   0,   0,\n",
       "         0,   0,   0,   0,  16,   0,   0,   0,   4,   0,   0,   0,  25,\n",
       "        13,  19, 100,  14,   6,   7,   0,  25,   0,   0,   0,  41,  35,\n",
       "        12, 100,  10,   0,   0,   0,  22,   0,   0,   0,   8,   5,  15,\n",
       "         0,  41,  17,  21,  80,   4,   0,   0,   0,  25,  44,  45, 100,\n",
       "        39,   4,   3,   0,  26,  18,  22,  80,  30,   4,   5,   0,   0,\n",
       "         0,  34,  22,  34,   0,  19,   7,  26,   5,  29,  94,  42,  70,\n",
       "         5,  57,  21,   0,  23,  82,  73,  77,  53,   7,  55,  32,   0,\n",
       "        37,  27,  18,  28, 100, 100, 100,  12,   5,  12,  84,  94,  84,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   0,  14,   0,\n",
       "         0,   0,  18,   0,  19,  10,   5,  10,  26,   9,  27,   7,  21,\n",
       "         0,  34,  40,  22,  39,  35,   8,  36,  67,  64,  63,  53,  34,\n",
       "        50,  24,   0,  27,  35,  35,  34,  69,  79,  69,  29,  33,  29,\n",
       "        49,  72,  36,   4,   0,  28,  29,  24,  45,  25,  46,  56,  52,\n",
       "        52,  23,  64,  19, 100, 100, 100,  10,   0,  11,  85, 100,  83,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  15,   0,  19,   0,\n",
       "         0,   0,  17,   0,  19,   9,   0,  11,  11,  14,  11,  40,  21,\n",
       "        34,  24,  23,  21,  77,  54,  65,  39,  22,  41,  10], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_features.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_features = cleaned_features.replace(-9223372036854775808, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cleaned_features.to_csv('all_features_sans_9223372036854775808.txt', encoding='utf-8', header=False, index=False) #for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACS_09_B08303_HD01_VD04_Estimate__10_to_14_minutes_100scale'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cleaned_features.columns)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "marital_ed_SNAP = cleaned_features[[ 'ACS_09_B12002_HD01_VD03_Estimate__Male__Never_married_100scale',\n",
    " 'ACS_09_B12002_HD01_VD04_Estimate__Male__Never_married__15_to_17_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD05_Estimate__Male__Never_married__18_and_19_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD06_Estimate__Male__Never_married__20_to_24_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD07_Estimate__Male__Never_married__25_to_29_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD08_Estimate__Male__Never_married__30_to_34_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD09_Estimate__Male__Never_married__35_to_39_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD19_Estimate__Male__Now_married__Married,_spouse_present_100scale',\n",
    " 'ACS_09_B12002_HD01_VD20_Estimate__Male__Now_married__Married,_spouse_present__15_to_17_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD21_Estimate__Male__Now_married__Married,_spouse_present__18_and_19_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD22_Estimate__Male__Now_married__Married,_spouse_present__20_to_24_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD23_Estimate__Male__Now_married__Married,_spouse_present__25_to_29_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD24_Estimate__Male__Now_married__Married,_spouse_present__30_to_34_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD25_Estimate__Male__Now_married__Married,_spouse_present__35_to_39_years_100scale',\n",
    "'ACS_09_B12002_HD01_VD127_Estimate__Female__Now_married__Married,_spouse_absent_100scale',\n",
    " 'ACS_09_B12002_HD01_VD128_Estimate__Female__Now_married__Married,_spouse_absent__Separated_100scale',\n",
    " 'ACS_09_B12002_HD01_VD129_Estimate__Female__Now_married__Married,_spouse_absent__Separated__15_to_17_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD130_Estimate__Female__Now_married__Married,_spouse_absent__Separated__18_and_19_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD131_Estimate__Female__Now_married__Married,_spouse_absent__Separated__20_to_24_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD132_Estimate__Female__Now_married__Married,_spouse_absent__Separated__25_to_29_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD133_Estimate__Female__Now_married__Married,_spouse_absent__Separated__30_to_34_years_100scale',\n",
    " 'ACS_09_B12002_HD01_VD134_Estimate__Female__Now_married__Married,_spouse_absent__Separated__35_to_39_years_100scale',\n",
    "'ACS_09_B19054_HD01_VD02_Estimate__With_interest,_dividends,_or_net_rental_income_100scale',\n",
    " 'ACS_09_B19054_HD01_VD03_Estimate__No_interest,_dividends,_or_net_rental_income_100scale',\n",
    " 'ACS_09_B19055_HD01_VD01_Estimate__Total_100scale',\n",
    " 'ACS_09_B19055_HD01_VD02_Estimate__With_Social_Security_income_100scale',\n",
    " 'ACS_09_B19055_HD01_VD03_Estimate__No_Social_Security_income_100scale',\n",
    " 'ACS_09_B25003_HD01_VD01_Estimate__Total_100scale',\n",
    " 'ACS_09_B25003_HD01_VD02_Estimate__Owner_occupied_100scale',\n",
    " 'ACS_09_B25003_HD01_VD03_Estimate__Renter_occupied_100scale',\n",
    "'ACS_09_S1301_HC03_EST_VC01_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years_100scale','ACS_09_S1301_HC04_EST_VC01_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC01_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC02_Total__Estimate__Women_15_to_50_years__15_to_19_years_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC02_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__15_to_19_years_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC02_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__15_to_19_years_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC02_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__15_to_19_years_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC03_Total__Estimate__Women_15_to_50_years__20_to_34_years_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC03_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__20_to_34_years_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC03_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__20_to_34_years_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC03_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__20_to_34_years_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC04_Total__Estimate__Women_15_to_50_years__35_to_50_years_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC04_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__35_to_50_years_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC04_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__35_to_50_years_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC04_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__35_to_50_years_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC06_Total__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC06_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC06_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC06_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC07_Total__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__White_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC07_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__White_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC07_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__White_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC07_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__White_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC08_Total__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Black_or_African_American_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC08_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Black_or_African_American_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC08_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Black_or_African_American_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC08_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Black_or_African_American_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC09_Total__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__American_Indian_and_Alaska_Native_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC09_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__American_Indian_and_Alaska_Native_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC09_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__American_Indian_and_Alaska_Native_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC09_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__American_Indian_and_Alaska_Native_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC10_Total__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Asian_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC10_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Asian_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC10_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Asian_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC10_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Asian_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC11_Total__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Native_Hawaiian_and_Other_Pacific_Islander_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC11_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Native_Hawaiian_and_Other_Pacific_Islander_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC11_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Native_Hawaiian_and_Other_Pacific_Islander_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC11_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Native_Hawaiian_and_Other_Pacific_Islander_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC12_Total__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Some_other_race_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC12_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Some_other_race_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC12_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Some_other_race_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC12_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__One_race__Some_other_race_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC13_Total__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__Two_or_more_races_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC13_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__Two_or_more_races_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC13_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__Two_or_more_races_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC13_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__Two_or_more_races_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC14_Total__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__Hispanic_or_Latino_origin_(of_any_race_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC14_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__Hispanic_or_Latino_origin_(of_any_race_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC14_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__Hispanic_or_Latino_origin_(of_any_race_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC14_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__Hispanic_or_Latino_origin_(of_any_race_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC15_Total__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__White_alone,_not_Hispanic_or_Latino_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC15_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__White_alone,_not_Hispanic_or_Latino_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC15_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__White_alone,_not_Hispanic_or_Latino_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC15_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__RACE_AND_HISPANIC_OR_LATINO_ORIGIN__White_alone,_not_Hispanic_or_Latino_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC17_Total__Estimate__Women_15_to_50_years__CITIZENSHIP_STATUS__Native_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC17_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__CITIZENSHIP_STATUS__Native_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC17_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__CITIZENSHIP_STATUS__Native_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC17_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__CITIZENSHIP_STATUS__Native_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC18_Total__Estimate__Women_15_to_50_years__CITIZENSHIP_STATUS__Foreign_born_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC18_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__CITIZENSHIP_STATUS__Foreign_born_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC18_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__CITIZENSHIP_STATUS__Foreign_born_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC18_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__CITIZENSHIP_STATUS__Foreign_born_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC20_Total__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Less_than_high_school_graduate_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC20_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Less_than_high_school_graduate_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC20_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Less_than_high_school_graduate_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC20_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Less_than_high_school_graduate_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC21_Total__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__High_school_graduate_(includes_equivalency_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC21_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__High_school_graduate_(includes_equivalency_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC21_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__High_school_graduate_(includes_equivalency_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC21_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__High_school_graduate_(includes_equivalency_100scale',\n",
    " \"ACS_09_S1301_HC01_EST_VC22_Total__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Some_college_or_associate's_degree_100scale\",\n",
    " \"ACS_09_S1301_HC03_EST_VC22_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Some_college_or_associate's_degree_100scale\",\n",
    " \"ACS_09_S1301_HC04_EST_VC22_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Some_college_or_associate's_degree_100scale\",\n",
    " \"ACS_09_S1301_HC05_EST_VC22_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Some_college_or_associate's_degree_100scale\",\n",
    " \"ACS_09_S1301_HC01_EST_VC23_Total__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Bachelor's_degree_100scale\",\n",
    " \"ACS_09_S1301_HC03_EST_VC23_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Bachelor's_degree_100scale\",\n",
    " \"ACS_09_S1301_HC04_EST_VC23_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Bachelor's_degree_100scale\",\n",
    " \"ACS_09_S1301_HC05_EST_VC23_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Bachelor's_degree_100scale\",\n",
    " 'ACS_09_S1301_HC01_EST_VC24_Total__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Graduate_or_professional_degree_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC24_Women_with_births_in_the_past_12_months__Number__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Graduate_or_professional_degree_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC24_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Graduate_or_professional_degree_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC24_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__Women_15_to_50_years__EDUCATIONAL_ATTAINMENT__Graduate_or_professional_degree_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC26_Total__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC26_Women_with_births_in_the_past_12_months__Number__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC26_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC26_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC27_Total__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__Below_100_percent_of_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC27_Women_with_births_in_the_past_12_months__Number__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__Below_100_percent_of_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC27_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__Below_100_percent_of_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC27_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__Below_100_percent_of_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC28_Total__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__100_to_199_percent_of_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC28_Women_with_births_in_the_past_12_months__Number__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__100_to_199_percent_of_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC28_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__100_to_199_percent_of_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC28_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__100_to_199_percent_of_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC01_EST_VC29_Total__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__200_percent_or_more_above_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC03_EST_VC29_Women_with_births_in_the_past_12_months__Number__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__200_percent_or_more_above_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC04_EST_VC29_Women_with_births_in_the_past_12_months__Rate_per_1,000_women__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__200_percent_or_more_above_poverty_level_100scale',\n",
    " 'ACS_09_S1301_HC05_EST_VC29_Percent__of_women_who_had_a_birth_in_the_past_12_months_who_were_unmarried__Estimate__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Women_15_to_50_years_for_whom_poverty_status_is_determined__200_percent_or_more_above_poverty_level_100scale',\n",
    "'ACS_09_S2201_HC02_EST_VC01_Households_receiving_food_stamps__Estimate__Households_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC01_Households_not_receiving_food_stamps__Estimate__Households_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC02_Total__Estimate__Households__With_one_or_more_people_60_years_and_over_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC02_Households_receiving_food_stamps__Estimate__Households__With_one_or_more_people_60_years_and_over_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC02_Households_not_receiving_food_stamps__Estimate__Households__With_one_or_more_people_60_years_and_over_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC03_Total__Estimate__Households__With_children_under_18_years_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC03_Households_receiving_food_stamps__Estimate__Households__With_children_under_18_years_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC03_Households_not_receiving_food_stamps__Estimate__Households__With_children_under_18_years_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC05_Total__Estimate__Households__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Below_poverty_level_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC05_Households_receiving_food_stamps__Estimate__Households__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Below_poverty_level_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC05_Households_not_receiving_food_stamps__Estimate__Households__POVERTY_STATUS_IN_THE_PAST_12_MONTHS__Below_poverty_level_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC09_Total__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC09_Households_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC09_Households_not_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC10_Total__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__White_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC10_Households_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__White_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC10_Households_not_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__White_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC11_Total__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Black_or_African_American_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC11_Households_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Black_or_African_American_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC11_Households_not_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Black_or_African_American_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC12_Total__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__American_Indian_and_Alaska_Native_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC12_Households_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__American_Indian_and_Alaska_Native_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC12_Households_not_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__American_Indian_and_Alaska_Native_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC13_Total__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Asian_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC13_Households_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Asian_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC13_Households_not_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Asian_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC14_Total__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Native_Hawaiian_and_Other_Pacific_Islander_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC14_Households_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Native_Hawaiian_and_Other_Pacific_Islander_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC14_Households_not_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Native_Hawaiian_and_Other_Pacific_Islander_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC15_Total__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Some_other_race_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC15_Households_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Some_other_race_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC15_Households_not_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__One_race__Some_other_race_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC16_Total__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__Two_or_more_races_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC16_Households_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__Two_or_more_races_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC16_Households_not_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__Two_or_more_races_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC17_Total__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__Hispanic_or_Latino_origin_(of_any_race_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC17_Households_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__Hispanic_or_Latino_origin_(of_any_race_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC17_Households_not_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__Hispanic_or_Latino_origin_(of_any_race_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC18_Total__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__White_alone,_not_Hispanic_or_Latino_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC18_Households_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__White_alone,_not_Hispanic_or_Latino_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC18_Households_not_receiving_food_stamps__Estimate__Households__RACE_AND_HISPANIC_OR_LATINO_ORIGIN_OF_HOUSEHOLDER__White_alone,_not_Hispanic_or_Latino_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC20_Total__Estimate__Households__HOUSEHOLD_INCOME_IN_THE_PAST_12_MONTHS_(IN_2009_INFLATIONADJUSTED_DOLLARS__Median_income_(dollars_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC20_Households_receiving_food_stamps__Estimate__Households__HOUSEHOLD_INCOME_IN_THE_PAST_12_MONTHS_(IN_2009_INFLATIONADJUSTED_DOLLARS__Median_income_(dollars_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC20_Households_not_receiving_food_stamps__Estimate__Households__HOUSEHOLD_INCOME_IN_THE_PAST_12_MONTHS_(IN_2009_INFLATIONADJUSTED_DOLLARS__Median_income_(dollars_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC22_Total__Estimate__WORK_STATUS__Families_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC22_Households_receiving_food_stamps__Estimate__WORK_STATUS__Families_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC22_Households_not_receiving_food_stamps__Estimate__WORK_STATUS__Families_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC23_Total__Estimate__WORK_STATUS__Families__No_workers_in_past_12_months_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC23_Households_receiving_food_stamps__Estimate__WORK_STATUS__Families__No_workers_in_past_12_months_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC23_Households_not_receiving_food_stamps__Estimate__WORK_STATUS__Families__No_workers_in_past_12_months_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC24_Total__Estimate__WORK_STATUS__Families__1_worker_in_past_12_months_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC24_Households_receiving_food_stamps__Estimate__WORK_STATUS__Families__1_worker_in_past_12_months_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC24_Households_not_receiving_food_stamps__Estimate__WORK_STATUS__Families__1_worker_in_past_12_months_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC25_Total__Estimate__WORK_STATUS__Families__2_or_more_workers_in_past_12_months_100scale',\n",
    " 'ACS_09_S2201_HC02_EST_VC25_Households_receiving_food_stamps__Estimate__WORK_STATUS__Families__2_or_more_workers_in_past_12_months_100scale',\n",
    " 'ACS_09_S2201_HC03_EST_VC25_Households_not_receiving_food_stamps__Estimate__WORK_STATUS__Families__2_or_more_workers_in_past_12_months_100scale',\n",
    " 'ACS_09_S2201_HC01_EST_VC27_Total__Estimate__PERCENT_IMPUTED__Food_stamp/SNAP_recipiency_100scale']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_array  = marital_ed_SNAP.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features_array, target, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CV scores:\n",
      "min: 0.902, mean: 0.904, max: 0.908\n",
      "Wall time: 754 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=100)\n",
    "# rf.fit(features_train, target_train)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None,\n",
    "min_samples_split=1, random_state=0)\n",
    "clf.fit(features_train,target_train)\n",
    "scores = cross_val_score(clf, features_train, target_train)\n",
    "scores.mean()      \n",
    "# scores = cross_val_score(features_array, target, cv=5, n_jobs=4,\n",
    "#                          scoring='accuracy')\n",
    "print(\"Random Forest CV scores:\")\n",
    "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
    "    scores.min(), scores.mean(), scores.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Trees CV scores:\n",
      "min: 0.857, mean: 0.884, max: 0.902\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "                                subsample=.8, max_features=.5)\n",
    "scores = cross_val_score(gb, features_train, target_train, cv=5, n_jobs=4,\n",
    "                         scoring='accuracy')\n",
    "print(\"Gradient Boosted Trees CV scores:\")\n",
    "print(\"min: {:.3f}, mean: {:.3f}, max: {:.3f}\".format(\n",
    "    scores.min(), scores.mean(), scores.max()))\n",
    "\n",
    "\n",
    "#Note Classification with more than 2 classes requires the induction of n_classes regression trees at each at\n",
    "#each iteration, thus, the total number of induced trees equals n_classes * n_estimators. For datasets with \n",
    "#a large number of classes I strongly recommend to use RandomForestClassifier as an alternative to GradientBoostingClassifier ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_predicted = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86928104575163401"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(target_test, target_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86928104575163401"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    gentrified       0.87      1.00      0.93       133\n",
      "not gentrified       0.00      0.00      0.00        20\n",
      "\n",
      "   avg / total       0.76      0.87      0.81       153\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\metrics\\classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#wow! 100% recall....\n",
    "\n",
    "print(classification_report(target_test, target_predicted,\n",
    "                            target_names=['gentrified', 'not gentrified']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_predicted_prob = clf.predict_proba(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "def plot_roc_curve(target_test, target_predicted_proba):\n",
    "    fpr, tpr, thresholds = roc_curve(target_test, target_predicted_proba[:, 1])\n",
    "    \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "    plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIwYARgwAjBgAmABg6FX4mYOz3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xad35048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(target_test,target_predicted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, features_array, target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87804878048780488, 0.90082644628099173, 0.89218714717969561)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.min(), scores.max(), scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48809523809523803, 0.52535306223830813, 0.59811227024341762)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, features_array, target, cv=3,\n",
    "                         scoring='roc_auc')\n",
    "scores.min(), scores.mean(), scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81691658587943417"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=1,\n",
    "random_state=0)\n",
    "scores = cross_val_score(clf, features_train, target_train)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89760050750762821"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "# min_samples_split=1, random_state=0) --->0.90415097458441107\n",
    "# clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "# min_samples_split=1, oob_score = True, random_state = 42) ---> 0.89760050750762821\n",
    "\n",
    "scores = cross_val_score(clf, features_train, target_train)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89979348996376851"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_forest = ExtraTreesClassifier(n_estimators=10, max_depth=None,\n",
    "min_samples_split=1, random_state=0)\n",
    "scores = cross_val_score(extra_forest, features_train, target_train)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.867075664622\n",
      "2 0.856850715746\n",
      "3 0.856850715746\n",
      "4 0.846625766871\n",
      "5 0.840490797546\n",
      "6 0.844580777096\n",
      "7 0.862985685072\n",
      "8 0.867075664622\n",
      "9 0.869120654397\n",
      "10 0.879345603272\n",
      "11 0.879345603272\n",
      "12 0.883435582822\n",
      "13 0.887525562372\n",
      "14 0.885480572597\n",
      "15 0.885480572597\n",
      "16"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.887525562372\n",
      "17 0.887525562372\n",
      "18 0.889570552147\n",
      "19 0.893660531697\n",
      "20 0.893660531697\n",
      "21 0.893660531697\n",
      "22 0.893660531697\n",
      "23 0.893660531697\n",
      "24 0.893660531697\n",
      "25 0.893660531697\n",
      "26 0.893660531697\n",
      "27 0.893660531697\n",
      "28 0.893660531697\n",
      "29 0.893660531697\n",
      "30 0.893660531697\n",
      "31 0.891615541922\n",
      "32 0.891615541922\n",
      "33 0.893660531697\n",
      "34 0.893660531697\n",
      "35 0.893660531697\n",
      "36 0.893660531697\n",
      "37 0.893660531697\n",
      "38 0.895705521472\n",
      "39 0.895705521472\n",
      "40 0.895705521472\n",
      "41 0.897750511247\n",
      "42 0.895705521472\n",
      "43 0.897750511247\n",
      "44 0.899795501022\n",
      "45 0.897750511247\n",
      "46 0.897750511247\n",
      "47 0.897750511247\n",
      "48 0.897750511247\n",
      "49 0.897750511247\n",
      "50 0.897750511247\n",
      "51 0.897750511247\n",
      "52 0.897750511247\n",
      "53 0.897750511247\n",
      "54 0.897750511247\n",
      "55 0.897750511247\n",
      "56 0.897750511247\n",
      "57 0.897750511247\n",
      "58 0.897750511247\n",
      "59 0.895705521472\n",
      "60 0.897750511247\n",
      "61 0.897750511247\n",
      "62 0.897750511247\n",
      "63 0.897750511247\n",
      "64 0.897750511247\n",
      "65 0.897750511247\n",
      "66 0.897750511247\n",
      "67 0.897750511247\n",
      "68 0.897750511247\n",
      "69 0.897750511247\n",
      "70 0.897750511247\n",
      "71 0.897750511247\n",
      "72 0.897750511247\n",
      "73 0.897750511247\n",
      "74 0.897750511247\n",
      "75 0.897750511247\n",
      "76 0.897750511247\n",
      "77 0.897750511247\n",
      "78 0.897750511247\n",
      "79 0.897750511247\n",
      "80 0.897750511247\n",
      "81 0.897750511247\n",
      "82 0.897750511247\n",
      "83 0.897750511247\n",
      "84 0.897750511247\n",
      "85 0.897750511247\n",
      "86 0.897750511247\n",
      "87 0.897750511247\n",
      "88 0.897750511247\n",
      "89 0.897750511247\n",
      "90 0.897750511247\n",
      "91 0.897750511247\n",
      "92 0.897750511247\n",
      "93 0.897750511247\n",
      "94 0.897750511247\n",
      "95 0.897750511247\n",
      "96 0.897750511247\n",
      "97 0.897750511247\n",
      "98 0.897750511247\n",
      "99 0.897750511247\n",
      "100 0.897750511247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\WinPython-64bit-3.4.3.5\\python-3.4.3.amd64\\lib\\site-packages\\sklearn\\ensemble\\forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    }
   ],
   "source": [
    "n_estimators = 100\n",
    "forest = RandomForestClassifier(warm_start=True, oob_score=True)\n",
    "\n",
    "for i in range(1, n_estimators + 1):\n",
    "    forest.set_params(n_estimators=i)\n",
    "    forest.fit(features_train, target_train)\n",
    "    print(i, forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, subsample=.8)\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.05, 0.1, 0.5],\n",
    "    'max_features': [0.5, 1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "}\n",
    "gs = GridSearchCV(gb, params, cv=5, scoring='roc_auc', n_jobs=4)\n",
    "gs.fit(features_array, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.54685, std: 0.09246, params: {'learning_rate': 0.1, 'max_features': 0.5, 'max_depth': 3},\n",
       " mean: 0.53404, std: 0.05865, params: {'learning_rate': 0.05, 'max_features': 0.5, 'max_depth': 5},\n",
       " mean: 0.53338, std: 0.06346, params: {'learning_rate': 0.05, 'max_features': 0.5, 'max_depth': 3},\n",
       " mean: 0.53126, std: 0.04829, params: {'learning_rate': 0.5, 'max_features': 0.5, 'max_depth': 5},\n",
       " mean: 0.52829, std: 0.09855, params: {'learning_rate': 0.5, 'max_features': 1, 'max_depth': 5},\n",
       " mean: 0.51870, std: 0.04368, params: {'learning_rate': 0.1, 'max_features': 0.5, 'max_depth': 5},\n",
       " mean: 0.51824, std: 0.04709, params: {'learning_rate': 0.1, 'max_features': 1, 'max_depth': 4},\n",
       " mean: 0.50949, std: 0.08312, params: {'learning_rate': 0.5, 'max_features': 1, 'max_depth': 4},\n",
       " mean: 0.50447, std: 0.07080, params: {'learning_rate': 0.5, 'max_features': 0.5, 'max_depth': 4},\n",
       " mean: 0.50339, std: 0.03092, params: {'learning_rate': 0.05, 'max_features': 1, 'max_depth': 4},\n",
       " mean: 0.50147, std: 0.06434, params: {'learning_rate': 0.5, 'max_features': 0.5, 'max_depth': 3},\n",
       " mean: 0.50062, std: 0.07200, params: {'learning_rate': 0.1, 'max_features': 1, 'max_depth': 3},\n",
       " mean: 0.49952, std: 0.04218, params: {'learning_rate': 0.05, 'max_features': 1, 'max_depth': 3},\n",
       " mean: 0.49329, std: 0.05204, params: {'learning_rate': 0.05, 'max_features': 0.5, 'max_depth': 4},\n",
       " mean: 0.49015, std: 0.05881, params: {'learning_rate': 0.1, 'max_features': 0.5, 'max_depth': 4},\n",
       " mean: 0.48864, std: 0.03659, params: {'learning_rate': 0.5, 'max_features': 1, 'max_depth': 3},\n",
       " mean: 0.46082, std: 0.04503, params: {'learning_rate': 0.05, 'max_features': 1, 'max_depth': 5},\n",
       " mean: 0.40426, std: 0.07328, params: {'learning_rate': 0.1, 'max_features': 1, 'max_depth': 5}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(gs.grid_scores_, key=lambda x: x.mean_validation_score, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "numberTrees = 100\n",
    "clf = RandomForestRegressor(n_estimators=numberTrees)\n",
    "clf.fit(features_train,target_train)\n",
    "for tree in range(numberTrees):\n",
    "#     print(clf.estimators_[tree].predict(val.irow(1)))\n",
    "    per_tree_pred = [tree.predict(features_train) for tree in clf.estimators_]\n",
    "#     print(per_tree_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0xaded5f8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEPCAYAAABcA4N7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLJeDwszMcjkozMwsl4PCzMxy/X/UzFFdNlWbLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x958bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "errors = []\n",
    "growing_rf = RandomForestClassifier(n_estimators=10, n_jobs=-1,  \n",
    "                                    warm_start=True, random_state=1000)\n",
    "for i in range(40):\n",
    "    growing_rf.fit(features_train, target_train)\n",
    "    growing_rf.n_estimators += 10\n",
    "    errors.append(log_loss(target, growing_rf.predict_proba(features_array)))\n",
    "\n",
    "_ = plt.plot(errors, '-r')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 178 (0.026612)\n",
      "2. feature 79 (0.014246)\n",
      "3. feature 3 (0.013927)\n",
      "4. feature 55 (0.013523)\n",
      "5. feature 172 (0.012936)\n",
      "6. feature 32 (0.012575)\n",
      "7. feature 170 (0.011721)\n",
      "8. feature 109 (0.011531)\n",
      "9. feature 17 (0.011525)\n",
      "10. feature 180 (0.011426)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncdI3M8uIk76ZWUac9M3MMuKkb2aWkf8PULImSq/WU+sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc7c1748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extra_forest.fit(features_train, target_train)\n",
    "importances = extra_forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in extra_forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(10):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(10), importances[indices][0:10],\n",
    "       color=\"r\", align=\"center\", yerr=std[indices][0:10])\n",
    "plt.xticks(range(10), indices)\n",
    "plt.xlim([-1, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score with the entire dataset = -0.22\n",
      "Score without the samples containing missing values = -0.57\n",
      "Score after imputation of the missing values = -0.20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "X_full, y_full = features_array, target\n",
    "n_samples = X_full.shape[0]\n",
    "n_features = X_full.shape[1]\n",
    "\n",
    "# Estimate the score on the entire dataset, with no missing values\n",
    "estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "score = cross_val_score(estimator, X_full, y_full).mean()\n",
    "print(\"Score with the entire dataset = %.2f\" % score)\n",
    "\n",
    "# Add missing values in 75% of the lines\n",
    "missing_rate = 0.75\n",
    "n_missing_samples = np.floor(n_samples * missing_rate)\n",
    "missing_samples = np.hstack((np.zeros(n_samples - n_missing_samples,\n",
    "                                      dtype=np.bool),\n",
    "                             np.ones(n_missing_samples,\n",
    "                                     dtype=np.bool)))\n",
    "rng.shuffle(missing_samples)\n",
    "missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "\n",
    "# Estimate the score without the lines containing missing values\n",
    "X_filtered = X_full[~missing_samples, :]\n",
    "y_filtered = y_full[~missing_samples]\n",
    "estimator = RandomForestRegressor(random_state=0, n_estimators=100)\n",
    "score = cross_val_score(estimator, X_filtered, y_filtered).mean()\n",
    "print(\"Score without the samples containing missing values = %.2f\" % score)\n",
    "\n",
    "# Estimate the score after imputation of the missing values\n",
    "X_missing = X_full.copy()\n",
    "X_missing[np.where(missing_samples)[0], missing_features] = 0\n",
    "y_missing = y_full.copy()\n",
    "estimator = Pipeline([(\"imputer\", Imputer(missing_values=0,\n",
    "                                          strategy=\"mean\",\n",
    "                                          axis=0)),\n",
    "                      (\"forest\", RandomForestRegressor(random_state=0,\n",
    "                                                       n_estimators=100))])\n",
    "score = cross_val_score(estimator, X_missing, y_missing).mean()\n",
    "print(\"Score after imputation of the missing values = %.2f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Finished fold with 1 / 186 feature ranks, score=0.485801\n",
      "Finished fold with 2 / 186 feature ranks, score=0.469833\n",
      "Finished fold with 3 / 186 feature ranks, score=0.544480\n",
      "Finished fold with 4 / 186 feature ranks, score=0.587306\n",
      "Finished fold with 5 / 186 feature ranks, score=0.559706\n",
      "Finished fold with 6 / 186 feature ranks, score=0.497719\n",
      "Finished fold with 7 / 186 feature ranks, score=0.548244\n",
      "Finished fold with 8 / 186 feature ranks, score=0.532333\n",
      "Finished fold with 9 / 186 feature ranks, score=0.540146\n",
      "Finished fold with 10 / 186 feature ranks, score=0.539005\n",
      "Finished fold with 11 / 186 feature ranks, score=0.516081\n",
      "Finished fold with 12 / 186 feature ranks, score=0.554288\n",
      "Finished fold with 13 / 186 feature ranks, score=0.578467\n",
      "Finished fold with 14 / 186 feature ranks, score=0.556969\n",
      "Finished fold with 15 / 186 feature ranks, score=0.554174\n",
      "Finished fold with 16 / 186 feature ranks, score=0.523609\n",
      "Finished fold with 17 / 186 feature ranks, score=0.548358\n",
      "Finished fold with 18 / 186 feature ranks, score=0.587819\n",
      "Finished fold with 19 / 186 feature ranks, score=0.503992\n",
      "Finished fold with 20 / 186 feature ranks, score=0.561531\n",
      "Finished fold with 21 / 186 feature ranks, score=0.549897\n",
      "Finished fold with 22 / 186 feature ranks, score=0.492986\n",
      "Finished fold with 23 / 186 feature ranks, score=0.568260\n",
      "Finished fold with 24 / 186 feature ranks, score=0.517393\n",
      "Finished fold with 25 / 186 feature ranks, score=0.533474\n",
      "Finished fold with 26 / 186 feature ranks, score=0.610573\n",
      "Finished fold with 27 / 186 feature ranks, score=0.526004\n",
      "Finished fold with 28 / 186 feature ranks, score=0.589131\n",
      "Finished fold with 29 / 186 feature ranks, score=0.496693\n",
      "Finished fold with 30 / 186 feature ranks, score=0.495495\n",
      "Finished fold with 31 / 186 feature ranks, score=0.532048\n",
      "Finished fold with 32 / 186 feature ranks, score=0.575331\n",
      "Finished fold with 33 / 186 feature ranks, score=0.565123\n",
      "Finished fold with 34 / 186 feature ranks, score=0.540545\n",
      "Finished fold with 35 / 186 feature ranks, score=0.533075\n",
      "Finished fold with 36 / 186 feature ranks, score=0.563412\n",
      "Finished fold with 37 / 186 feature ranks, score=0.476562\n",
      "Finished fold with 38 / 186 feature ranks, score=0.569856\n",
      "Finished fold with 39 / 186 feature ranks, score=0.547844\n",
      "Finished fold with 40 / 186 feature ranks, score=0.597970\n",
      "Finished fold with 41 / 186 feature ranks, score=0.583828\n",
      "Finished fold with 42 / 186 feature ranks, score=0.562956\n",
      "Finished fold with 43 / 186 feature ranks, score=0.531079\n",
      "Finished fold with 44 / 186 feature ranks, score=0.566891\n",
      "Finished fold with 45 / 186 feature ranks, score=0.457858\n",
      "Finished fold with 46 / 186 feature ranks, score=0.479471\n",
      "Finished fold with 47 / 186 feature ranks, score=0.387945\n",
      "Finished fold with 48 / 186 feature ranks, score=0.513344\n",
      "Finished fold with 49 / 186 feature ranks, score=0.534615\n",
      "Finished fold with 50 / 186 feature ranks, score=0.490705\n",
      "Finished fold with 51 / 186 feature ranks, score=0.578809\n",
      "Finished fold with 52 / 186 feature ranks, score=0.550240\n",
      "Finished fold with 53 / 186 feature ranks, score=0.522867\n",
      "Finished fold with 54 / 186 feature ranks, score=0.552007\n",
      "Finished fold with 55 / 186 feature ranks, score=0.533474\n",
      "Finished fold with 56 / 186 feature ranks, score=0.537922\n",
      "Finished fold with 57 / 186 feature ranks, score=0.508041\n",
      "Finished fold with 58 / 186 feature ranks, score=0.515454\n",
      "Finished fold with 59 / 186 feature ranks, score=0.505589\n",
      "Finished fold with 60 / 186 feature ranks, score=0.408759\n",
      "Finished fold with 61 / 186 feature ranks, score=0.562101\n",
      "Finished fold with 62 / 186 feature ranks, score=0.480155\n",
      "Finished fold with 63 / 186 feature ranks, score=0.569229\n",
      "Finished fold with 64 / 186 feature ranks, score=0.536325\n",
      "Finished fold with 65 / 186 feature ranks, score=0.473312\n",
      "Finished fold with 66 / 186 feature ranks, score=0.563355\n",
      "Finished fold with 67 / 186 feature ranks, score=0.462363\n",
      "Finished fold with 68 / 186 feature ranks, score=0.524122\n",
      "Finished fold with 69 / 186 feature ranks, score=0.519788\n",
      "Finished fold with 70 / 186 feature ranks, score=0.597343\n",
      "Finished fold with 71 / 186 feature ranks, score=0.516651\n",
      "Finished fold with 72 / 186 feature ranks, score=0.488367\n",
      "Finished fold with 73 / 186 feature ranks, score=0.471886\n",
      "Finished fold with 74 / 186 feature ranks, score=0.504904\n",
      "Finished fold with 75 / 186 feature ranks, score=0.525148\n",
      "Finished fold with 76 / 186 feature ranks, score=0.564325\n",
      "Finished fold with 77 / 186 feature ranks, score=0.485801\n",
      "Finished fold with 78 / 186 feature ranks, score=0.497662\n",
      "Finished fold with 79 / 186 feature ranks, score=0.482721\n",
      "Finished fold with 80 / 186 feature ranks, score=0.568146\n",
      "Finished fold with 81 / 186 feature ranks, score=0.484261\n",
      "Finished fold with 82 / 186 feature ranks, score=0.514085\n",
      "Finished fold with 83 / 186 feature ranks, score=0.581261\n",
      "Finished fold with 84 / 186 feature ranks, score=0.468408\n",
      "Finished fold with 85 / 186 feature ranks, score=0.559193\n",
      "Finished fold with 86 / 186 feature ranks, score=0.488937\n",
      "Finished fold with 87 / 186 feature ranks, score=0.606809\n",
      "Finished fold with 88 / 186 feature ranks, score=0.541629\n",
      "Finished fold with 89 / 186 feature ranks, score=0.563184\n",
      "Finished fold with 90 / 186 feature ranks, score=0.513743\n",
      "Finished fold with 91 / 186 feature ranks, score=0.498688\n",
      "Finished fold with 92 / 186 feature ranks, score=0.502509\n",
      "Finished fold with 93 / 186 feature ranks, score=0.495666\n",
      "Finished fold with 94 / 186 feature ranks, score=0.530452\n",
      "Finished fold with 95 / 186 feature ranks, score=0.507242\n",
      "Finished fold with 96 / 186 feature ranks, score=0.556797\n",
      "Finished fold with 97 / 186 feature ranks, score=0.464017\n",
      "Finished fold with 98 / 186 feature ranks, score=0.534786\n",
      "Finished fold with 99 / 186 feature ranks, score=0.519047\n",
      "Finished fold with 100 / 186 feature ranks, score=0.483691\n",
      "Finished fold with 101 / 186 feature ranks, score=0.552635\n",
      "Finished fold with 102 / 186 feature ranks, score=0.502053\n",
      "Finished fold with 103 / 186 feature ranks, score=0.636063\n",
      "Finished fold with 104 / 186 feature ranks, score=0.514656\n",
      "Finished fold with 105 / 186 feature ranks, score=0.490534\n",
      "Finished fold with 106 / 186 feature ranks, score=0.544765\n",
      "Finished fold with 107 / 186 feature ranks, score=0.548928\n",
      "Finished fold with 108 / 186 feature ranks, score=0.523038\n",
      "Finished fold with 109 / 186 feature ranks, score=0.474738\n",
      "Finished fold with 110 / 186 feature ranks, score=0.561359\n",
      "Finished fold with 111 / 186 feature ranks, score=0.564667\n",
      "Finished fold with 112 / 186 feature ranks, score=0.566492\n",
      "Finished fold with 113 / 186 feature ranks, score=0.424783\n",
      "Finished fold with 114 / 186 feature ranks, score=0.502224\n",
      "Finished fold with 115 / 186 feature ranks, score=0.545849\n",
      "Finished fold with 116 / 186 feature ranks, score=0.531877\n",
      "Finished fold with 117 / 186 feature ranks, score=0.544480\n",
      "Finished fold with 118 / 186 feature ranks, score=0.462420\n",
      "Finished fold with 119 / 186 feature ranks, score=0.499316\n",
      "Finished fold with 120 / 186 feature ranks, score=0.450046\n",
      "Finished fold with 121 / 186 feature ranks, score=0.549270\n",
      "Finished fold with 122 / 186 feature ranks, score=0.542997\n",
      "Finished fold with 123 / 186 feature ranks, score=0.565979\n",
      "Finished fold with 124 / 186 feature ranks, score=0.446396\n",
      "Finished fold with 125 / 186 feature ranks, score=0.446966\n",
      "Finished fold with 126 / 186 feature ranks, score=0.537067\n",
      "Finished fold with 127 / 186 feature ranks, score=0.527372\n",
      "Finished fold with 128 / 186 feature ranks, score=0.529938\n",
      "Finished fold with 129 / 186 feature ranks, score=0.535869\n",
      "Finished fold with 130 / 186 feature ranks, score=0.531193\n",
      "Finished fold with 131 / 186 feature ranks, score=0.563869\n",
      "Finished fold with 132 / 186 feature ranks, score=0.602589\n",
      "Finished fold with 133 / 186 feature ranks, score=0.509409\n",
      "Finished fold with 134 / 186 feature ranks, score=0.569058\n",
      "Finished fold with 135 / 186 feature ranks, score=0.492758\n",
      "Finished fold with 136 / 186 feature ranks, score=0.470518\n",
      "Finished fold with 137 / 186 feature ranks, score=0.557197\n",
      "Finished fold with 138 / 186 feature ranks, score=0.607664\n",
      "Finished fold with 139 / 186 feature ranks, score=0.502224\n",
      "Finished fold with 140 / 186 feature ranks, score=0.507470\n",
      "Finished fold with 141 / 186 feature ranks, score=0.447594\n",
      "Finished fold with 142 / 186 feature ranks, score=0.464188\n",
      "Finished fold with 143 / 186 feature ranks, score=0.526574\n",
      "Finished fold with 144 / 186 feature ranks, score=0.540089\n",
      "Finished fold with 145 / 186 feature ranks, score=0.539576\n",
      "Finished fold with 146 / 186 feature ranks, score=0.515796\n",
      "Finished fold with 147 / 186 feature ranks, score=0.593864\n",
      "Finished fold with 148 / 186 feature ranks, score=0.568716\n",
      "Finished fold with 149 / 186 feature ranks, score=0.542541\n",
      "Finished fold with 150 / 186 feature ranks, score=0.530794\n",
      "Finished fold with 151 / 186 feature ranks, score=0.578296\n",
      "Finished fold with 152 / 186 feature ranks, score=0.551038\n",
      "Finished fold with 153 / 186 feature ranks, score=0.505417\n",
      "Finished fold with 154 / 186 feature ranks, score=0.601620\n",
      "Finished fold with 155 / 186 feature ranks, score=0.469035\n",
      "Finished fold with 156 / 186 feature ranks, score=0.534729\n",
      "Finished fold with 157 / 186 feature ranks, score=0.569286\n",
      "Finished fold with 158 / 186 feature ranks, score=0.599110\n",
      "Finished fold with 159 / 186 feature ranks, score=0.443031\n",
      "Finished fold with 160 / 186 feature ranks, score=0.476962\n",
      "Finished fold with 161 / 186 feature ranks, score=0.506615\n",
      "Finished fold with 162 / 186 feature ranks, score=0.570141\n",
      "Finished fold with 163 / 186 feature ranks, score=0.527030\n",
      "Finished fold with 164 / 186 feature ranks, score=0.462135\n",
      "Finished fold with 165 / 186 feature ranks, score=0.601334\n",
      "Finished fold with 166 / 186 feature ranks, score=0.439439\n",
      "Finished fold with 167 / 186 feature ranks, score=0.517507\n",
      "Finished fold with 168 / 186 feature ranks, score=0.565066\n",
      "Finished fold with 169 / 186 feature ranks, score=0.578809\n",
      "Finished fold with 170 / 186 feature ranks, score=0.530224\n",
      "Finished fold with 171 / 186 feature ranks, score=0.525034\n",
      "Finished fold with 172 / 186 feature ranks, score=0.501426\n",
      "Finished fold with 173 / 186 feature ranks, score=0.522639\n",
      "Finished fold with 174 / 186 feature ranks, score=0.617473\n",
      "Finished fold with 175 / 186 feature ranks, score=0.522069\n",
      "Finished fold with 176 / 186 feature ranks, score=0.511063\n",
      "Finished fold with 177 / 186 feature ranks, score=0.554516\n",
      "Finished fold with 178 / 186 feature ranks, score=0.509751\n",
      "Finished fold with 179 / 186 feature ranks, score=0.633440\n",
      "Finished fold with 180 / 186 feature ranks, score=0.503764\n",
      "Finished fold with 181 / 186 feature ranks, score=0.522810\n",
      "Finished fold with 182 / 186 feature ranks, score=0.447651\n",
      "Finished fold with 183 / 186 feature ranks, score=0.517507\n",
      "Finished fold with 184 / 186 feature ranks, score=0.548301\n",
      "Finished fold with 185 / 186 feature ranks, score=0.537808\n",
      "Finished fold with 186 / 186 feature ranks, score=0.526631\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 6 features.\n",
      "Fitting estimator with 5 features.\n",
      "Fitting estimator with 4 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 2 features.\n",
      "Finished fold with 1 / 186 feature ranks, score=0.564838\n",
      "Finished fold with 2 / 186 feature ranks, score=0.456204\n",
      "Finished fold with 3 / 186 feature ranks, score=0.477703\n",
      "Finished fold with 4 / 186 feature ranks, score=0.481638\n",
      "Finished fold with 5 / 186 feature ranks, score=0.451699\n",
      "Finished fold with 6 / 186 feature ranks, score=0.502794\n",
      "Finished fold with 7 / 186 feature ranks, score=0.517963\n",
      "Finished fold with 8 / 186 feature ranks, score=0.486884\n",
      "Finished fold with 9 / 186 feature ranks, score=0.462762\n",
      "Finished fold with 10 / 186 feature ranks, score=0.467724\n",
      "Finished fold with 11 / 186 feature ranks, score=0.471145\n",
      "Finished fold with 12 / 186 feature ranks, score=0.470689\n",
      "Finished fold with 13 / 186 feature ranks, score=0.475479\n",
      "Finished fold with 14 / 186 feature ranks, score=0.498175\n",
      "Finished fold with 15 / 186 feature ranks, score=0.488310\n",
      "Finished fold with 16 / 186 feature ranks, score=0.465728\n",
      "Finished fold with 17 / 186 feature ranks, score=0.476391\n",
      "Finished fold with 18 / 186 feature ranks, score=0.455919\n",
      "Finished fold with 19 / 186 feature ranks, score=0.449247\n",
      "Finished fold with 20 / 186 feature ranks, score=0.452156\n",
      "Finished fold with 21 / 186 feature ranks, score=0.446282\n",
      "Finished fold with 22 / 186 feature ranks, score=0.436474\n",
      "Finished fold with 23 / 186 feature ranks, score=0.442176\n",
      "Finished fold with 24 / 186 feature ranks, score=0.468180\n",
      "Finished fold with 25 / 186 feature ranks, score=0.516024\n",
      "Finished fold with 26 / 186 feature ranks, score=0.538435\n",
      "Finished fold with 27 / 186 feature ranks, score=0.511861\n",
      "Finished fold with 28 / 186 feature ranks, score=0.485573\n",
      "Finished fold with 29 / 186 feature ranks, score=0.501483\n",
      "Finished fold with 30 / 186 feature ranks, score=0.498802\n",
      "Finished fold with 31 / 186 feature ranks, score=0.500000\n",
      "Finished fold with 32 / 186 feature ranks, score=0.473882\n",
      "Finished fold with 33 / 186 feature ranks, score=0.444742\n",
      "Finished fold with 34 / 186 feature ranks, score=0.510094\n",
      "Finished fold with 35 / 186 feature ranks, score=0.454494\n",
      "Finished fold with 36 / 186 feature ranks, score=0.502794\n",
      "Finished fold with 37 / 186 feature ranks, score=0.494811\n",
      "Finished fold with 38 / 186 feature ranks, score=0.460538\n",
      "Finished fold with 39 / 186 feature ranks, score=0.464473\n",
      "Finished fold with 40 / 186 feature ranks, score=0.519959\n",
      "Finished fold with 41 / 186 feature ranks, score=0.519503\n",
      "Finished fold with 42 / 186 feature ranks, score=0.513458\n",
      "Finished fold with 43 / 186 feature ranks, score=0.476448\n",
      "Finished fold with 44 / 186 feature ranks, score=0.590899\n",
      "Finished fold with 45 / 186 feature ranks, score=0.511405\n",
      "Finished fold with 46 / 186 feature ranks, score=0.435504\n",
      "Finished fold with 47 / 186 feature ranks, score=0.471772\n",
      "Finished fold with 48 / 186 feature ranks, score=0.439610\n",
      "Finished fold with 49 / 186 feature ranks, score=0.461451\n",
      "Finished fold with 50 / 186 feature ranks, score=0.500513\n",
      "Finished fold with 51 / 186 feature ranks, score=0.560618\n",
      "Finished fold with 52 / 186 feature ranks, score=0.490192\n",
      "Finished fold with 53 / 186 feature ranks, score=0.511804\n",
      "Finished fold with 54 / 186 feature ranks, score=0.418796\n",
      "Finished fold with 55 / 186 feature ranks, score=0.530680\n",
      "Finished fold with 56 / 186 feature ranks, score=0.458656\n",
      "Finished fold with 57 / 186 feature ranks, score=0.456490\n",
      "Finished fold with 58 / 186 feature ranks, score=0.528114\n",
      "Finished fold with 59 / 186 feature ranks, score=0.551950\n",
      "Finished fold with 60 / 186 feature ranks, score=0.534900\n",
      "Finished fold with 61 / 186 feature ranks, score=0.527828\n",
      "Finished fold with 62 / 186 feature ranks, score=0.528741\n",
      "Finished fold with 63 / 186 feature ranks, score=0.472229\n",
      "Finished fold with 64 / 186 feature ranks, score=0.533474\n",
      "Finished fold with 65 / 186 feature ranks, score=0.476220\n",
      "Finished fold with 66 / 186 feature ranks, score=0.517963\n",
      "Finished fold with 67 / 186 feature ranks, score=0.455634\n",
      "Finished fold with 68 / 186 feature ranks, score=0.527600\n",
      "Finished fold with 69 / 186 feature ranks, score=0.472400\n",
      "Finished fold with 70 / 186 feature ranks, score=0.538321\n",
      "Finished fold with 71 / 186 feature ranks, score=0.507584\n",
      "Finished fold with 72 / 186 feature ranks, score=0.468066\n",
      "Finished fold with 73 / 186 feature ranks, score=0.488880\n",
      "Finished fold with 74 / 186 feature ranks, score=0.579151\n",
      "Finished fold with 75 / 186 feature ranks, score=0.454665\n",
      "Finished fold with 76 / 186 feature ranks, score=0.518990\n",
      "Finished fold with 77 / 186 feature ranks, score=0.480383\n",
      "Finished fold with 78 / 186 feature ranks, score=0.433736\n",
      "Finished fold with 79 / 186 feature ranks, score=0.421476\n",
      "Finished fold with 80 / 186 feature ranks, score=0.500114\n",
      "Finished fold with 81 / 186 feature ranks, score=0.452783\n",
      "Finished fold with 82 / 186 feature ranks, score=0.482322\n",
      "Finished fold with 83 / 186 feature ranks, score=0.517051\n",
      "Finished fold with 84 / 186 feature ranks, score=0.508098\n",
      "Finished fold with 85 / 186 feature ranks, score=0.537865\n",
      "Finished fold with 86 / 186 feature ranks, score=0.539576\n",
      "Finished fold with 87 / 186 feature ranks, score=0.535755\n",
      "Finished fold with 88 / 186 feature ranks, score=0.484147\n",
      "Finished fold with 89 / 186 feature ranks, score=0.486542\n",
      "Finished fold with 90 / 186 feature ranks, score=0.476505\n",
      "Finished fold with 91 / 186 feature ranks, score=0.511006\n",
      "Finished fold with 92 / 186 feature ranks, score=0.443773\n",
      "Finished fold with 93 / 186 feature ranks, score=0.545221\n",
      "Finished fold with 94 / 186 feature ranks, score=0.514142\n",
      "Finished fold with 95 / 186 feature ranks, score=0.534158\n",
      "Finished fold with 96 / 186 feature ranks, score=0.518647\n",
      "Finished fold with 97 / 186 feature ranks, score=0.440750\n",
      "Finished fold with 98 / 186 feature ranks, score=0.515967\n",
      "Finished fold with 99 / 186 feature ranks, score=0.474224\n",
      "Finished fold with 100 / 186 feature ranks, score=0.506786\n",
      "Finished fold with 101 / 186 feature ranks, score=0.601334\n",
      "Finished fold with 102 / 186 feature ranks, score=0.534786\n",
      "Finished fold with 103 / 186 feature ranks, score=0.524920\n",
      "Finished fold with 104 / 186 feature ranks, score=0.511120\n",
      "Finished fold with 105 / 186 feature ranks, score=0.502452\n",
      "Finished fold with 106 / 186 feature ranks, score=0.530737\n",
      "Finished fold with 107 / 186 feature ranks, score=0.518248\n",
      "Finished fold with 108 / 186 feature ranks, score=0.458371\n",
      "Finished fold with 109 / 186 feature ranks, score=0.472057\n",
      "Finished fold with 110 / 186 feature ranks, score=0.491446\n",
      "Finished fold with 111 / 186 feature ranks, score=0.523038\n",
      "Finished fold with 112 / 186 feature ranks, score=0.493157\n",
      "Finished fold with 113 / 186 feature ranks, score=0.465956\n",
      "Finished fold with 114 / 186 feature ranks, score=0.567347\n",
      "Finished fold with 115 / 186 feature ranks, score=0.478786\n",
      "Finished fold with 116 / 186 feature ranks, score=0.526289\n",
      "Finished fold with 117 / 186 feature ranks, score=0.539062\n",
      "Finished fold with 118 / 186 feature ranks, score=0.452555\n",
      "Finished fold with 119 / 186 feature ranks, score=0.555942\n",
      "Finished fold with 120 / 186 feature ranks, score=0.506615\n",
      "Finished fold with 121 / 186 feature ranks, score=0.481410\n",
      "Finished fold with 122 / 186 feature ranks, score=0.496065\n",
      "Finished fold with 123 / 186 feature ranks, score=0.463903\n",
      "Finished fold with 124 / 186 feature ranks, score=0.465956\n",
      "Finished fold with 125 / 186 feature ranks, score=0.436417\n",
      "Finished fold with 126 / 186 feature ranks, score=0.541344\n",
      "Finished fold with 127 / 186 feature ranks, score=0.501026\n",
      "Finished fold with 128 / 186 feature ranks, score=0.567005\n",
      "Finished fold with 129 / 186 feature ranks, score=0.507527\n",
      "Finished fold with 130 / 186 feature ranks, score=0.478729\n",
      "Finished fold with 131 / 186 feature ranks, score=0.604585\n",
      "Finished fold with 132 / 186 feature ranks, score=0.466754\n",
      "Finished fold with 133 / 186 feature ranks, score=0.477076\n",
      "Finished fold with 134 / 186 feature ranks, score=0.510493\n",
      "Finished fold with 135 / 186 feature ranks, score=0.569229\n",
      "Finished fold with 136 / 186 feature ranks, score=0.478901\n",
      "Finished fold with 137 / 186 feature ranks, score=0.523951\n",
      "Finished fold with 138 / 186 feature ranks, score=0.489678\n",
      "Finished fold with 139 / 186 feature ranks, score=0.572422\n",
      "Finished fold with 140 / 186 feature ranks, score=0.485116\n",
      "Finished fold with 141 / 186 feature ranks, score=0.556455\n",
      "Finished fold with 142 / 186 feature ranks, score=0.549099\n",
      "Finished fold with 143 / 186 feature ranks, score=0.581547\n",
      "Finished fold with 144 / 186 feature ranks, score=0.512089\n",
      "Finished fold with 145 / 186 feature ranks, score=0.522981\n",
      "Finished fold with 146 / 186 feature ranks, score=0.561645\n",
      "Finished fold with 147 / 186 feature ranks, score=0.538663\n",
      "Finished fold with 148 / 186 feature ranks, score=0.523837\n",
      "Finished fold with 149 / 186 feature ranks, score=0.532505\n",
      "Finished fold with 150 / 186 feature ranks, score=0.485972\n",
      "Finished fold with 151 / 186 feature ranks, score=0.527828\n",
      "Finished fold with 152 / 186 feature ranks, score=0.529995\n",
      "Finished fold with 153 / 186 feature ranks, score=0.502509\n",
      "Finished fold with 154 / 186 feature ranks, score=0.508554\n",
      "Finished fold with 155 / 186 feature ranks, score=0.554174\n",
      "Finished fold with 156 / 186 feature ranks, score=0.439724\n",
      "Finished fold with 157 / 186 feature ranks, score=0.455349\n",
      "Finished fold with 158 / 186 feature ranks, score=0.495153\n",
      "Finished fold with 159 / 186 feature ranks, score=0.536211\n",
      "Finished fold with 160 / 186 feature ranks, score=0.555771\n",
      "Finished fold with 161 / 186 feature ranks, score=0.532904\n",
      "Finished fold with 162 / 186 feature ranks, score=0.467895\n",
      "Finished fold with 163 / 186 feature ranks, score=0.464017\n",
      "Finished fold with 164 / 186 feature ranks, score=0.497947\n",
      "Finished fold with 165 / 186 feature ranks, score=0.478045\n",
      "Finished fold with 166 / 186 feature ranks, score=0.482607\n",
      "Finished fold with 167 / 186 feature ranks, score=0.455634\n",
      "Finished fold with 168 / 186 feature ranks, score=0.492016\n",
      "Finished fold with 169 / 186 feature ranks, score=0.466868\n",
      "Finished fold with 170 / 186 feature ranks, score=0.515967\n",
      "Finished fold with 171 / 186 feature ranks, score=0.461280\n",
      "Finished fold with 172 / 186 feature ranks, score=0.565750\n",
      "Finished fold with 173 / 186 feature ranks, score=0.547787\n",
      "Finished fold with 174 / 186 feature ranks, score=0.511747\n",
      "Finished fold with 175 / 186 feature ranks, score=0.508725\n",
      "Finished fold with 176 / 186 feature ranks, score=0.472571\n",
      "Finished fold with 177 / 186 feature ranks, score=0.441492\n",
      "Finished fold with 178 / 186 feature ranks, score=0.527543\n",
      "Finished fold with 179 / 186 feature ranks, score=0.449532\n",
      "Finished fold with 180 / 186 feature ranks, score=0.588732\n",
      "Finished fold with 181 / 186 feature ranks, score=0.514713\n",
      "Finished fold with 182 / 186 feature ranks, score=0.471601\n",
      "Finished fold with 183 / 186 feature ranks, score=0.509181\n",
      "Finished fold with 184 / 186 feature ranks, score=0.500798\n",
      "Finished fold with 185 / 186 feature ranks, score=0.558679\n",
      "Finished fold with 186 / 186 feature ranks, score=0.572194\n"
     ]
    }
   ],
   "source": [
    "#http://stackoverflow.com/questions/24123498/recursive-feature-elimination-on-random-forest-using-scikit-learn?rq=1\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "def get_enhanced_confusion_matrix(actuals, predictions, labels):\n",
    "    \"\"\"\"enhances confusion_matrix by adding sensivity and specificity metrics\"\"\"\n",
    "    cm = confusion_matrix(actuals, predictions, labels = labels)\n",
    "    sensitivity = float(cm[1][1]) / float(cm[1][0]+cm[1][1])\n",
    "    specificity = float(cm[0][0]) / float(cm[0][0]+cm[0][1])\n",
    "    weightedAccuracy = (sensitivity * 0.9) + (specificity * 0.1)\n",
    "    return cm, sensitivity, specificity, weightedAccuracy\n",
    "\n",
    "\n",
    "x= features_array\n",
    "# print(x.shape)\n",
    "y= target\n",
    "# print(target.shape)\n",
    "\n",
    "\n",
    "class RandomForestClassifierWithCoef(RandomForestClassifier):\n",
    "    def fit(self, *args, **kwargs):\n",
    "        super(RandomForestClassifierWithCoef, self).fit(*args, **kwargs)\n",
    "        self.coef_ = self.feature_importances_\n",
    "\n",
    "rf = RandomForestClassifierWithCoef(n_estimators=10, min_samples_leaf=5, n_jobs=-1)\n",
    "rfecv = RFECV(estimator=rf, step=1, cv=2, scoring='roc_auc', verbose=2)\n",
    "selector=rfecv.fit(x, y)\n",
    "\n",
    "# # iris = datasets.load_iris()\n",
    "# # x=pandas.DataFrame(iris.data, columns=['var1','var2','var3', 'var4'])\n",
    "# # y=pandas.Series(iris.target, name='target')\n",
    "\n",
    "response, _  = pd.factorize(y)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = cross_validation.train_test_split(x, response, test_size = .25, random_state = 36583)\n",
    "print(\"building the first forest\")\n",
    "rf = RandomForestClassifier(n_estimators = 500, min_samples_split = 2, n_jobs = -1, verbose = 1)\n",
    "rf.fit(xTrain, yTrain)\n",
    "importances = pd.DataFrame({'name':x.columns,'imp':rf.feature_importances_\n",
    "                                }).sort(['imp'], ascending = False).reset_index(drop = True)\n",
    "\n",
    "cm, sensitivity, specificity, weightedAccuracy = get_enhanced_confusion_matrix(yTest, rf.predict(xTest), [0,1])\n",
    "numFeatures = len(x.columns)\n",
    "\n",
    "rfeMatrix = pandas.DataFrame({'numFeatures':[numFeatures], \n",
    "                              'weightedAccuracy':[weightedAccuracy], \n",
    "                              'sensitivity':[sensitivity], \n",
    "                              'specificity':[specificity]})\n",
    "\n",
    "print(\"running RFE on  %d features\"%numFeatures)\n",
    "\n",
    "for i in range(1,numFeatures,1):\n",
    "    varsUsed = importances['name'][0:i]\n",
    "    print(\"now using %d of %s features\"%(len(varsUsed), numFeatures))\n",
    "    xTrain, xTest, yTrain, yTest = cross_validation.train_test_split(x[varsUsed], response, test_size = .25)\n",
    "    rf = RandomForestClassifier(n_estimators = 500, min_samples_split = 2,\n",
    "                                n_jobs = -1, verbose = 1)\n",
    "    rf.fit(xTrain, yTrain)\n",
    "    cm, sensitivity, specificity, weightedAccuracy = get_enhanced_confusion_matrix(yTest, rf.predict(xTest), [0,1])\n",
    "    print(\"\\n\"+str(cm))\n",
    "    print('the sensitivity is %d percent'%(sensitivity * 100))\n",
    "    print('the specificity is %d percent'%(specificity * 100))\n",
    "    print('the weighted accuracy is %d percent'%(weightedAccuracy * 100))\n",
    "    rfeMatrix = rfeMatrix.append(\n",
    "                                pd.DataFrame({'numFeatures':[len(varsUsed)], \n",
    "                                'weightedAccuracy':[weightedAccuracy], \n",
    "                                'sensitivity':[sensitivity], \n",
    "                                'specificity':[specificity]}), ignore_index = True)    \n",
    "print(\"\\n\"+str(rfeMatrix))    \n",
    "maxAccuracy = rfeMatrix.weightedAccuracy.max()\n",
    "maxAccuracyFeatures = min(rfeMatrix.numFeatures[rfeMatrix.weightedAccuracy == maxAccuracy])\n",
    "featuresUsed = importances['name'][0:maxAccuracyFeatures].tolist()\n",
    "\n",
    "print(\"the final features used are %s\"%featuresUsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
